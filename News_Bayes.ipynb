{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "fs = glob.glob(\"chinese_news_test/*/*[tT][xX][tT]\")\n",
    "cats = []\n",
    "contents = []\n",
    "for fname in fs:\n",
    "    fn = os.path.split(fname)[-1]\n",
    "    with open(fname, \"r\", encoding = \"utf8\") as f:\n",
    "        content = f.read()\n",
    "        contents.append(content)\n",
    "    dn = os.path.split(fname)[0]\n",
    "    dn = os.path.split(dn)[-1]\n",
    "    cats.append(dn)\n",
    "    \n",
    "test_df = pd.DataFrame({\n",
    "    \"content\": contents,\n",
    "    \"ans\":cats\n",
    "}\n",
    ")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = glob.glob(\"chinese_news_trans/*/*[tT][xX][tT]\")\n",
    "cats = []\n",
    "contents = []\n",
    "for fname in fs:\n",
    "    fn = os.path.split(fname)[-1]\n",
    "    with open(fname, \"r\", encoding = \"utf8\") as f:\n",
    "        content = f.read()\n",
    "        contents.append(content)\n",
    "    dn = os.path.split(fname)[0]\n",
    "    dn = os.path.split(dn)[-1]\n",
    "    cats.append(dn)\n",
    "    \n",
    "train_df = pd.DataFrame({\n",
    "    \"content\": contents,\n",
    "    \"ans\":cats\n",
    "}\n",
    ")\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.set_dictionary('dict.txt.big')\n",
    "def cut(s):\n",
    "    s = s.replace(\"\\r\", \"\").replace(\"\\r\", \"\")\n",
    "    return \" \".join(jieba.cut(s))\n",
    "\n",
    "# apply: pandas operation to the all row\n",
    "x_train = train_df[\"content\"].apply(cut)\n",
    "x_test = test_df[\"content\"].apply(cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = train_df[\"ans\"].unique()\n",
    "trans = {label:i for i, label in enumerate(u)}\n",
    "\n",
    "# trans = {\n",
    "#     \"交通\": 0,\n",
    "#     \"政治\": 1,\n",
    "#     \"計算機\": 2,\n",
    "#     \"軍事\": 3,\n",
    "#     \"教育\": 4,\n",
    "#     \"經濟\": 5,\n",
    "#     \"環境\": 6,\n",
    "#     \"醫藥\": 7,\n",
    "#     \"藝術\": 8,\n",
    "#     \"體育\": 9\n",
    "# }\n",
    "reverse_trans = {v:k for k,v in trans.items()}\n",
    "y_train = train_df[\"ans\"].replace(trans)\n",
    "y_test = test_df[\"ans\"].replace(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Naive bayes can filter the important variables. Therefore, we don't use TfidfVectorizer\n",
    "vec = CountVectorizer()\n",
    "x_train_vec = vec.fit_transform(x_train)\n",
    "x_test_vec = vec.transform(x_test)\n",
    "# vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# The feature value is discrete.\n",
    "# GaussianNB: the feature value is continuous.\n",
    "# BernouliNB: the feature value is binary.\n",
    "clf = MultinomialNB(alpha = 1)\n",
    "clf.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pre = clf.predict(x_test_vec)\n",
    "accuracy_score(y_test, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, pre)\n",
    "ls = [\"交通\", \"政治\", \"計算機\", \"軍事\", \"教育\", \"經濟\", \"環境\", \"醫藥\", \"藝術\", \"體育\"]\n",
    "i = [n + \"(真實)\" for n in ls]\n",
    "c = [n + \"(預測)\" for n in ls]\n",
    "pd.DataFrame(mat,\n",
    "            columns = c,\n",
    "            index = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = []\n",
    "p = []\n",
    "while True:\n",
    "    a = input(\"請輸入新聞：\")\n",
    "    if a == \"0\":\n",
    "        break\n",
    "    else:\n",
    "        p_list.append(a)\n",
    "\n",
    "for x in range(0, len(p_list)):\n",
    "    review = cut(p_list[x])\n",
    "    p.append(review)\n",
    "    \n",
    "# p = vec.transform(p).toarray()\n",
    "p = vec.transform(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = clf.predict(p)\n",
    "for i in range(len(pre)):\n",
    "    print(\"*\" * 30)\n",
    "    print(\"這個新聞是：\", reverse_trans[pre[i]])\n",
    "    print(\"*\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_list = clf.predict_proba(p)\n",
    "\n",
    "for i in range(0, len(proba_list)):\n",
    "    single = list(zip(trans, proba_list[i]))\n",
    "    proba_list_single = sorted(single, reverse = True, key = lambda x:x[1])\n",
    "    for l,pn in proba_list_single:\n",
    "        print(\"第\",i+1,\"則新聞的\", \"類別：\",l, \"，機率：\", pn)\n",
    "    print(\"*\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
